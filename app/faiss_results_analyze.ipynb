{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, ast\n",
    "    \n",
    "import library as lib\n",
    "from library import GlobalVars\n",
    "import faiss_experiment as faiss_tool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#concatenate the results from multiple rounds in order to agregate the results\n",
    "lib.concat_csvs([\n",
    "            GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round1.csv', \\\n",
    "            GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round2.csv', \\\n",
    "            GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round3.csv',\\\n",
    "            GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round4.csv',\\\n",
    "            GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round4.csv'], GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_values(df):\n",
    "    # Grupuri logice\n",
    "    time_cols = ['train_time_min', 'predict_time_min']\n",
    "    memory_cols = ['train_used_memory_min']\n",
    "\n",
    "    # 1. Concatenăm valorile din cele 2 coloane de timp și normalizăm împreună\n",
    "    all_time_values = pd.concat([df[col] for col in time_cols])\n",
    "    min_time = all_time_values.min()\n",
    "    max_time = all_time_values.max()\n",
    "\n",
    "    # Normalizare pe ambele coloane de timp\n",
    "    for col in time_cols:\n",
    "        df[f\"{col}_scaled\"] = (df[col] - min_time) / (max_time - min_time)\n",
    "\n",
    "    # 2. La fel pentru memorie\n",
    "    all_memory_values = pd.concat([df[col] for col in memory_cols])\n",
    "    min_mem = all_memory_values.min()\n",
    "    max_mem = all_memory_values.max()\n",
    "\n",
    "    for col in memory_cols:\n",
    "        df[f\"{col}_scaled\"] = (df[col] - min_mem) / (max_mem - min_mem)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def format_time_on_plot(time_value):\n",
    "    return f\"{time_value:.4f}\"\n",
    "\n",
    "def format_size_on_plot(size_value):\n",
    "    return (f\"{size_value:.2f}\")\n",
    "\n",
    "def represent_index_performances_v3(df, group_field, image_name, use_index_memory = True, use_train_time = True, angle_label=90):\n",
    "    accuracy_field = \"accuracy_max\"\n",
    "    x = range(len(df))\n",
    "    x_labels = df[group_field] #.apply(lambda item: ast.literal_eval(item)[\"params\"])\n",
    "    bar_width = 0.2\n",
    "\n",
    "    df = scale_values(df)\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "    if (use_train_time):\n",
    "        ax.bar([p - bar_width for p in x], df['train_time_min_scaled'], width=bar_width, label='Timp construire index (s)', color='orange')\n",
    "    ax.bar(x, df['predict_time_min_scaled'], width=bar_width, label='Timp Predictie (s)', color='goldenrod')\n",
    "\n",
    "\n",
    "    # Bare pentru memorie (2)\n",
    "    if (use_index_memory):\n",
    "        ax.bar([p + bar_width for p in x], df['train_used_memory_min_scaled'], width=bar_width, label='Dimeniune Index (MB)', color='steelblue')\n",
    "\n",
    "    # Linie pentru accuracy\n",
    "    ax.plot([p + bar_width for p in x], df[accuracy_field], color='black', marker='o', linewidth=2, label='Accuratete (%)')\n",
    "\n",
    "    # Afișare valori reale pe linia de accuracy\n",
    "    for i, row in df.iterrows():\n",
    "        text_pos_y = row[accuracy_field] + 0.02\n",
    "        ax.text(i + bar_width, text_pos_y, f\"{100 * row[accuracy_field]:.2f}%\", ha='center', va='bottom', fontsize=9, color='black')\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        if (use_train_time):\n",
    "            ax.text(i - bar_width - 0.01, row['train_time_min_scaled'] + 0.02, format_time_on_plot(row['train_time_min']), ha='center', va='bottom', fontsize=8)        \n",
    "        ax.text(i, row['predict_time_min_scaled'] + 0.02, format_time_on_plot(row['predict_time_min']), ha='center', va='bottom', fontsize=8)\n",
    "        if (use_index_memory):\n",
    "            ax.text(i + bar_width, row['train_used_memory_min_scaled'], format_size_on_plot(row['train_used_memory_min']), ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x_labels, rotation=angle_label, ha='right')\n",
    "    plt.grid(False)\n",
    "    #plt.grid(True, which='major', axis='y', linestyle='--', linewidth=0.2, color='gray')\n",
    "    #plt.grid(True, which='major', axis='x', linestyle='--', linewidth=0.2, color='gray')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_name, format=\"svg\")\n",
    "    plt.show()\n",
    "\n",
    "def extract_all_faiss_results(results_file_path, group_field = 'indexFactory', sort_by = 'accuracy_max', sort_ascending=False):\n",
    "    df = pd.read_csv(results_file_path)\n",
    "    \n",
    "    #df = df[df['index_params'].str.contains('PQ')]\n",
    "    agg_columns = ['accuracy', 'train_time', 'predict_time', 'train_used_memory', 'predict_used_memory']\n",
    "\n",
    "    try:\n",
    "        df['indexTypeMilvus'] = df['index_params'].apply(lambda item: ast.literal_eval(item).get(\"index_type\"))\n",
    "        df['nListmilvus'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"params\").get(\"nlist\")))\n",
    "        df['pq_m_milvus'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"params\").get(\"m\", \"\")))\n",
    "        df['nprobeMilvus'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"nprobe\")))\n",
    "        df['indexFactoryMilvus'] = 'IVF' + df['nListmilvus'] + df['indexTypeMilvus'].str.replace('IVF_FLAT', ',Flat')\n",
    "        df['indexFactoryMilvus'] = df['indexFactoryMilvus'].str.replace('IVF_SQ8', ',SQ8') \n",
    "        \n",
    "        df['indexFactoryMilvus'] = np.where(df['indexTypeMilvus']=='IVF_PQ', 'IVF' + df['nListmilvus'] + \",PQ\" + df['pq_m_milvus'].astype(str), df['indexFactoryMilvus'])        \n",
    "        df['indexFactoryMilvus2'] = df['indexTypeMilvus'] + \"-\" + df['nListmilvus'] + \"-\" + df['nprobeMilvus'] \n",
    "        df = df[df['pq_m_milvus'] != '8'] #exclude PQ8 \n",
    "    except Exception as e:\n",
    "        print(\"Error generating milvus fields:\", e)\n",
    "        pass\n",
    "    df['indexFactory'] = df['index_params'].apply(lambda item: ast.literal_eval(item).get(\"params\"))\n",
    "    df['nprobe'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"nprobe\")))\n",
    "    df['efConstruction'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"efConstruction\")))\n",
    "    df['efSearch'] = df['index_params'].apply(lambda item: str(ast.literal_eval(item).get(\"efSearch\")))\n",
    "    try:\n",
    "        df['indexFactory_full1'] = df['indexFactory'] + \"-\" + df['nprobe']\n",
    "        df['indexFactory_full2'] = df['indexFactory'] + \"-\" + df['efConstruction']\n",
    "        df['indexFactory_full3'] = df['indexFactory'] + \"-\" + df['efConstruction'] + \"-\" + df['efSearch']\n",
    "    except:\n",
    "        print(\"Error generating other index fields:\", e)\n",
    "        pass\n",
    "        \n",
    "    #df = df[df['index_params'].str.contains(',PQ')]\n",
    "    #print(df.head(100).to_string())\n",
    "    result = df.groupby(group_field)[agg_columns].agg(['min', 'mean', 'max'])\n",
    "    result.columns = ['_'.join(col).strip() for col in result.columns.values]\n",
    "    result = result.reset_index()\n",
    "\n",
    "    # Sorting based on accuracy descending\n",
    "    result = result.sort_values(by=sort_by, ascending=sort_ascending)\n",
    "    result = result.reset_index(drop=True)\n",
    "    df_reduced = result[[group_field, 'accuracy_min', 'accuracy_mean', 'accuracy_max', 'train_used_memory_min', 'train_time_min', 'predict_time_min']].copy()\n",
    "    \n",
    "    df_formated = df_reduced.copy()\n",
    "    for col in ['accuracy_min', 'accuracy_mean', 'accuracy_max']:\n",
    "        df_formated[col] = df_formated[col] *100\n",
    "        df_formated[col] = df_formated[col].apply(lambda x: f\"{x:.2f}%\")\n",
    "    df_formated[\"train_used_memory_min\"] = df_formated[\"train_used_memory_min\"].map(lambda x: f\"{x:.2f}\")\n",
    "    df_formated[\"train_time_min\"] = df_formated[\"train_time_min\"].map(lambda x: f\"{x:.4f}\")\n",
    "    df_formated[\"predict_time_min\"] = df_formated[\"predict_time_min\"].map(lambda x: f\"{x:.4f}\")\n",
    "    print(df_formated.to_string(index=True))\n",
    "    return df_reduced\n",
    "\n",
    "results_file_path = GlobalVars.experiments_path + 'executed_faiss_experiments_index_ivf_all_round_all.csv'\n",
    "group_field = 'indexFactory_full2'\n",
    "df = extract_all_faiss_results(results_file_path, group_field)\n",
    "represent_index_performances_v3(df, group_field,  \"index_hnsw_results_bigdataset.svg\", angle_label = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file_path='experiments' + os.sep + '20250620_executed_knn_configs_results_v3_all.csv'\n",
    "df_sorted = lib.load_resuls_file(results_file_path)\n",
    "top1_n = 50\n",
    "top2_n = 100\n",
    "df_top1, df_top2 = lib.print_results_stat(df_sorted, top1_n, top2_n)\n",
    "\n",
    "\n",
    "df_cosine = df_sorted[df_sorted['metric_type'] == 'cosine']\n",
    "df_correlation = df_sorted[df_sorted['metric_type'] == 'correlation']\n",
    "print('Cosine avg train time (s):', df_cosine['train_time'].mean(), \"Train memory:\", df_cosine['train_used_memory'].mean(),  \"Predict time (S)\", df_cosine['predict_time'].mean(), \"Predict memory (MB):\", df_cosine['predict_used_memory'].mean())\n",
    "print('correlation avg train time (s):', df_correlation['train_time'].mean(), \"Train memory:\", df_correlation['train_used_memory'].mean(), \"Predict time (S)\", df_correlation['predict_time'].mean(), \"Predict memory (MB):\", df_correlation['predict_used_memory'].mean())\n",
    "\n",
    "\n",
    "lucky_winner = {}\n",
    "# lucky_winner['segment_lenght'] = lib.display_one_param_pie(\"segment_lenght\", df_sorted, df_top100, df_top200, 200, 100, \"Segment lenght\")\n",
    "# #lucky_winner['segment_overlap'] = lib.display_one_param_pie(\"segment_overlap\", df_sorted, df_top100, df_top200, 200, 100, \"Segment Overlap\")\n",
    "# lib.display_2params_pie(\"segment_lenght\", \"segment_overlap\", df_sorted, df_top100, df_top200, 200, 100, \"Segment lenght and Overlap\")\n",
    "# lucky_winner['feature'] = lib.display_one_param_pie(\"feature\", df_sorted, df_top100, df_top200, 200, 100, \"Applied feature\")\n",
    "lucky_winner['vector_operation'] = lib.display_one_param_pie(\"vector_operation\", df_sorted, df_top1, df_top2, top1_n, top2_n, \"Feature Agregation\")\n",
    "#lib.display_2params_pie(\"feature\", \"vector_operation\", df_sorted, df_top100, df_top200, 200, 100, \"Feature and agregation\")\n",
    "lucky_winner['metric_type'] = lib.display_one_param_pie(\"metric_type\", df_sorted, df_top1, df_top2, top1_n, top2_n, \"Metric Type\")\n",
    "lucky_winner['vote_type'] = lib.display_one_param_pie(\"vote_type\", df_sorted, df_top1, df_top2, top1_n, top2_n, \"Vote Type\")\n",
    "lucky_winner['neighbors'] = lib.display_one_param_pie(\"neighbors\", df_sorted, df_top1, df_top2, top1_n, top2_n, \"Index Param\")\n",
    "\n",
    "faiss_tool.report_results(results_file_path, 20)\n",
    "\n",
    "#results_file_path='experiments' + os.sep + 'knn_comparations.csv'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beesproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
